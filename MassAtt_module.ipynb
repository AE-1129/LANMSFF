{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3stgXmt5dNI"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "from random import randint\n",
        "import math\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.initializers import Constant,he_uniform\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Lambda, ReLU, Add,Dropout, Activation, Flatten, Input, PReLU,SeparableConv2D, Conv2DTranspose,concatenate,Convolution2D,ZeroPadding2D,Add,MaxPool2D\n",
        "from tensorflow.keras.layers import Conv2D,Conv2DTranspose, Activation,MaxPooling3D, MaxPooling2D, BatchNormalization, UpSampling2D,AveragePooling2D,GlobalMaxPooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import categorical_crossentropy, binary_crossentropy, mean_squared_error,sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam,Adamax,Nadam,Ftrl,RMSprop,Adadelta\n",
        "from tensorflow.keras.regularizers import l2,l1\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler, TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def MassAtt(input_tensor, ratio=4):\n",
        "\n",
        "        # Channel Attention Map\n",
        "        num_input_channels = input_tensor.shape[-1]\n",
        "        # Squeeze operation: Global average pooling\n",
        "        squeeze = GlobalAveragePooling2D()(input_tensor)\n",
        "        squeeze = Reshape((1,1,num_input_channels))(squeeze)\n",
        "        # Excitation operation: Two fully connected layers\n",
        "        excitation = tf.keras.layers.Dense(units=num_input_channels // ratio, activation='relu')(squeeze)\n",
        "        channel_att_map = tf.keras.layers.Dense(units=num_input_channels, activation='sigmoid')(excitation)\n",
        "\n",
        "\n",
        "        # Spatial Attention Map\n",
        "        spatial_attention = Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_tensor)\n",
        "        x= tf.keras.layers.Conv2D(filters= 2,kernel_size=3,kernel_initializer='he_uniform',activation='relu',strides=2,padding='same')(spatial_attention)\n",
        "        x= tf.keras.layers.Conv2D(filters= 4,kernel_size=3,kernel_initializer='he_uniform',activation='relu',strides=2,padding='same')(x)\n",
        "        x = Conv2DTranspose(4, (3, 3), activation='relu', padding='same',strides=2)(x)\n",
        "        spatial_att_map = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same',strides=2)(x)\n",
        "\n",
        "        # attention\n",
        "        attention= channel_att_map * spatial_att_map\n",
        "\n",
        "        return attention\n"
      ]
    }
  ]
}